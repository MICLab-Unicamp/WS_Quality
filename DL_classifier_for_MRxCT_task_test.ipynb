{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0Y0-LIdEw5f"
   },
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzkSJ_nAe-WK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator \n",
    "\n",
    "Keras does not have a generator that reads h5.\n",
    "Pytorch handles h5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqz6Dpnvoixp"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import sklearn.feature_extraction.image as ski\n",
    "\n",
    "def create_patches(x1,params,bs):\n",
    "  \n",
    "    x2 = np.zeros((bs,params.psize[0],params.psize[1],params.nch),dtype='float')\n",
    "\n",
    "    for i1 in np.arange(bs):\n",
    "        x2[i1,:,:,0] = ski.extract_patches_2d(x1[i1,:,:,:],(params.psize[0],params.psize[1]),max_patches=params.npt)\n",
    "\n",
    "        x2[i1,:,:,0] -= np.min(x2[i1,:,:,0])\n",
    "        x2[i1,:,:,0] /= np.max(x2[i1,:,:,0])\n",
    "\n",
    "\n",
    "    x2[:,:,:,1] = x2[:,:,:,0]\n",
    "    x2[:,:,:,2] = x2[:,:,:,0]\n",
    "    x2 -= .5\n",
    "    x2 *= 2\n",
    "    \n",
    "    return x2\n",
    "\n",
    "\n",
    "def generate_batches(files, idxt, params):\n",
    "    nn = len(files)\n",
    "    counter = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        hdf5_file1 = h5py.File(files[counter], \"r\")\n",
    "        print(hdf5_file1[\"labels\"].shape)\n",
    "\n",
    "        for cbatch in np.arange(0,idxt.shape[0],params.batch_size):\n",
    "            idx = idxt[cbatch:(cbatch+params.batch_size)]\n",
    "            idx.sort()\n",
    "\n",
    "            x1 = (hdf5_file1[\"img\"][idx,:,:,:])\n",
    "            y1 = (hdf5_file1[\"labels\"][idx,:2])\n",
    "\n",
    "            x11 = create_patches(x1,params,idx.shape[0])\n",
    "\n",
    "            yield (x11,y1)\n",
    "\n",
    "        hdf5_file1.close()\n",
    "\n",
    "        counter += 1\n",
    "        if counter == nn:\n",
    "            counter = 0 \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep CNN classifier using keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qBkchGDFKa4"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, argparse\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.regularizers import l1\n",
    "\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras_applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVOHudAtGZoO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def run_CNN(params):\n",
    "\n",
    "    f = 0\n",
    "    gen_test = generate_batches(files=[params.input+\"test.hdf5\"], idxt=np.arange(11494), params=params)\n",
    "\n",
    "    model,model_name,loadmdl = MyModel(params,f)\n",
    "\n",
    "    print('sgd = Adam(lr=3e-3)')\n",
    "    sgd = Adam(3e-3)\n",
    "\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(\"Compiled...\") \n",
    "\n",
    "    nsamplesperfold = 1.*params.ntrans*params.npt/(params.batch_size)\n",
    "\n",
    "    eval1 = model.evaluate_generator(gen_test, steps=11494,\n",
    "                   verbose=1)\n",
    "    print(eval1)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjFWzBSYKw-7"
   },
   "outputs": [],
   "source": [
    "def MyModel(params,f):\n",
    "\n",
    "  \n",
    "    model_name = params.models+str(f)+\"epochs:002-val_acc:0.960.hdf5epochs:005-val_acc:0.999.hdf5\"\n",
    "    if not os.path.isfile(model_name ):\n",
    "        print(\"Creating Model : \", model_name)\n",
    "        model_base = ResNet50V2(include_top=False, weights='imagenet', input_shape=(params.psize[0], params.psize[1],params.nch), pooling='avg',backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "        x = model_base.get_layer('avg_pool').output\n",
    "        dense = Dense(2,\n",
    "                    kernel_initializer='he_normal',\n",
    "                    bias_initializer='zeros',\n",
    "                    kernel_regularizer=l1(0.01),\n",
    "                    name='classifier')(x)\n",
    "  \n",
    "        prediction = Activation(\"softmax\",name=\"softmax\")(dense)\n",
    "\n",
    "        model = Model(model_base.inputs, outputs=prediction, name='ResNet')\n",
    "\n",
    "        loadmdl = 0\n",
    "    else:\n",
    "        print(\"Loading model: \", model_name)\n",
    "        model_base = ResNet50V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(params.psize[0], params.psize[1],params.nch), pooling='avg', classes=3)\n",
    "\n",
    "        x = model_base.get_layer('avg_pool').output\n",
    "        dense = Dense(2,\n",
    "                    kernel_initializer='he_normal',\n",
    "                    bias_initializer='zeros',\n",
    "                    kernel_regularizer=l1(0.01),\n",
    "                    name='classifier')(x)\n",
    "  \n",
    "        prediction = Activation(\"softmax\",name=\"softmax\")(dense)\n",
    "\n",
    "        model = Model(model_base.inputs, outputs=prediction, name='ResNet')\n",
    "      \n",
    "        model.load_weights(model_name)\n",
    "\n",
    "\n",
    "        loadmdl = 1\n",
    "\n",
    "\n",
    "    return model,model_name,loadmdl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "7sgEWS9PLxHa",
    "outputId": "052f577b-1838-4bba-f393-3defb86f9b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model:  /content/drive/My Drive/model_BrainHack_CTMR_h5_0epochs:002-val_acc:0.960.hdf5epochs:005-val_acc:0.999.hdf5\n",
      "sgd = Adam(lr=3e-3)\n",
      "Compiled...\n",
      "(11494, 15)\n",
      " 1139/11494 [=>............................] - ETA: 9:48\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b(11494, 15)\n",
      " 2289/11494 [====>.........................] - ETA: 8:27(11494, 15)\n",
      "(11494, 15) 3440/11494 [=======>......................]\n",
      " 4590/11494 [==========>...................] - ETA: 6:12(11494, 15)\n",
      " 5739/11494 [=============>................] - ETA: 5:08\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b(11494, 15)\n",
      " 6890/11494 [================>.............] - ETA: 4:06(11494, 15)\n",
      "(11494, 15) 8040/11494 [===================>..........]\n",
      " 9190/11494 [======================>.......](11494, 15) - ETA: 2:02\n",
      "10338/11494 [=========================>....] - ETA: 1:01\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b(11494, 15)\n",
      "11489/11494 [============================>.] - ETA: 0s(11494, 15)\n",
      "11494/11494 [==============================] - 612s 53ms/step\n",
      "[0.018093021989381432, 0.9988684433396807]\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['foo']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-input',\n",
    "                    type=str,\n",
    "                    default='/home/ubuntu/volume1/BrainHack/data/BrainHack_quality_',\n",
    "                    help='txt file containing input data filenames')\n",
    "\n",
    "parser.add_argument('-models', type=str, \n",
    "                    default='/home/ubuntu/volume1/BrainHack/models/model_BrainHack_CTMR_h5_',\n",
    "                    help='models prefix directory')\n",
    "\n",
    "parser.add_argument('-psize', type=int, default=[128,128],\n",
    "                    help='patch size extracted from dataset')\n",
    "\n",
    "parser.add_argument('-window', type=int, default=[224,224],\n",
    "                    help='area of interest ')\n",
    "\n",
    "parser.add_argument('-img_size', type=int, default=[224,224],\n",
    "                    help='area of interest ')\n",
    "\n",
    "parser.add_argument('-nfolds', type=int, default=1,\n",
    "                    help='number of folds for training')\n",
    "\n",
    "parser.add_argument('-nch', type=int, default=3,\n",
    "                    help='number of input channels')\n",
    "\n",
    "parser.add_argument('-npt', type=int, default=1,\n",
    "                    help='the number of patches from slices')\n",
    "\n",
    "parser.add_argument('-ntrans', type=int, default=5,\n",
    "                    help='number of transformations ')\n",
    "\n",
    "parser.add_argument('-batch_size', type=int, default=10,\n",
    "                    help='size of batch')\n",
    "\n",
    "params = parser.parse_args()\n",
    "\n",
    "run_CNN(params)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Test_GPU Workshop_MR_CT_h5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
